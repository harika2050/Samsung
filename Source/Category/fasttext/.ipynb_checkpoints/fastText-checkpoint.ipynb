{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "36lKILlYqO-y",
    "outputId": "f98c2030-a369-4e46-c15c-554dbaa3fbf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install googledrivedownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Ji1f6cAtqpMh",
    "outputId": "0a6facce-62f8-45f5-9d4b-39d124c25bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1jlzvS4GF56vfxb5Wm_4-TrUgICz4KYDs into ./data/news.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1jlzvS4GF56vfxb5Wm_4-TrUgICz4KYDs',\n",
    "                                    dest_path='./data/news.zip',\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3A6klJ4qqU5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-R4VGiMtqqaf"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "x0Rg7jy6qqhP",
    "outputId": "bf7b2611-7016-4b95-f1d3-9c29cd4235b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>win over cena satisfying but defeating underta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>raju chacha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>status quo will not be disturbed at ayodhya sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fissures in hurriyat over pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>america unwanted heading for india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  win over cena satisfying but defeating underta...\n",
       "1                                        raju chacha\n",
       "2  status quo will not be disturbed at ayodhya sa...\n",
       "3                fissures in hurriyat over pak visit\n",
       "4                 america unwanted heading for india"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../Data/category-data/news-files/india-news-headlines.csv')\n",
    "df = df.drop(['publish_date','headline_category'], axis=1)\n",
    "df.columns = ['text']\n",
    "df['text'] = df['text'].apply(lambda x: clean_text(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FY2A-Cd-q3UP",
    "outputId": "cca5f4da-f7f3-46f9-8cdf-9f447a536998"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sail quarters are on sale'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = df.text.to_list()\n",
    "sentences[2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Cy7PUJAqqnf"
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'w') as fout:\n",
    "  for sent in sentences:\n",
    "    fout.write(\"%s\\n\" %sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "j5dJCGqdqqtr",
    "outputId": "311100f5-dd0a-4085-e15b-20644729fcb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastText'...\n",
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 3488 (delta 0), reused 2 (delta 0), pack-reused 3483\u001b[K\n",
      "Receiving objects: 100% (3488/3488), 8.01 MiB | 5.70 MiB/s, done.\n",
      "Resolving deltas: 100% (2193/2193), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "gpKrMItMqqza",
    "outputId": "dbf50464-9ae4-423c-b7f2-89b8fc587aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/fastText\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n"
     ]
    }
   ],
   "source": [
    "%cd fastText\n",
    "! make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Uh-TaI4jraQB",
    "outputId": "561211b5-b4ad-423c-ba33-94310be238cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "total 130404\n",
      "drwxr-xr-x  2 root root      4096 Sep  8 11:55 data\n",
      "drwxr-xr-x 12 root root      4096 Sep  8 11:57 fastText\n",
      "drwxr-xr-x  2 root root      4096 Sep  8 11:57 model\n",
      "drwxr-xr-x  1 root root      4096 Aug 27 16:17 sample_data\n",
      "-rw-r--r--  1 root root 133513401 Sep  8 11:57 train.txt\n",
      "/content/fastText\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "! mkdir model\n",
    "! ls -l\n",
    "%cd fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "DVpodkj4qq5W",
    "outputId": "0f62ec13-acb8-41f2-f90b-84489de4a1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25M words\n",
      "Number of words:  70654\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   15155 lr:  0.000000 avg.loss:  1.447002 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "! ./fasttext skipgram -input ../train.txt -output ../model/fasttext-model -epoch 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IoZvFVLYqq-7",
    "outputId": "17314072-6a7c-4e32-8734-8937f001143f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, Embedding, LSTM, SpatialDropout1D, Flatten\n",
    "from keras.layers import GRU, Bidirectional, Convolution1D, GlobalMaxPool1D, TimeDistributed, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kJeyHWjqrDg"
   },
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "model = FastText.load_fasttext_format('../model/fasttext-model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-yMRcpR_2Jg"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    if len(text.split()) < 8:\n",
    "      return np.nan\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Dt4xwUh2qrJR",
    "outputId": "36f659b8-2435-44d0-ffe2-1077838391d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1t2bs-j0ZWmh6igA9miD4d8WJaUOCF7nI into ./dummy.csv... Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id='1t2bs-j0ZWmh6igA9miD4d8WJaUOCF7nI',\n",
    "                                    dest_path='./dummy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ape19LPOzhJq",
    "outputId": "9edf9dd1-e6bf-4483-960a-cd3f30343c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df Shape: (638842, 17)\n",
      "Dataset shape: (636494, 16)\n",
      "Length of df: 636494\n",
      "Length of labels: 636494\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dummy.csv')\n",
    "print('df Shape:', df.shape)\n",
    "df = df.where(df['video']==0).dropna()\n",
    "df = df.drop('video', axis=1)\n",
    "df['id'] = df['id'].astype('int64')\n",
    "for col in df.columns[2:]:\n",
    "    df[col] = df[col].astype('int8')\n",
    "print('Dataset shape:', df.shape)\n",
    "df['headline'] = df['headline'].apply(lambda text: clean_text(text))\n",
    "df = df.dropna()\n",
    "print('Length of df:', len(df))\n",
    "\n",
    "labels = np.argmax(df.iloc[:, 2:].values, axis=1).tolist()\n",
    "print('Length of labels:', len(labels))\n",
    "\n",
    "df['labels'] = labels\n",
    "df = df.iloc[:, [1,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "-GiR62Lfzjh8",
    "outputId": "60a8cc4a-eb62-4548-dcce-5b92d48883f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (509195,)\n",
      "valid_x shape: (127299,)\n",
      "train_y shape: (509195, 14)\n",
      "valid_y shape: (127299, 14)\n"
     ]
    }
   ],
   "source": [
    "X = df['headline']\n",
    "y = pd.get_dummies(df.labels)\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = tts(X, y, test_size=0.2, random_state=0)\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('valid_x shape:', valid_x.shape)\n",
    "print('train_y shape:', train_y.shape)\n",
    "print('valid_y shape:', valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbTRUv_2zkzn"
   },
   "outputs": [],
   "source": [
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(X)\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKNH1PXVzmWT"
   },
   "outputs": [],
   "source": [
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=60)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JKNMmIZszn1t",
    "outputId": "eec61c81-e29d-492a-b3fc-87b24448264d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 out of 99693 words absent\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, 100))\n",
    "ct = 0\n",
    "for word, i in word_index.items():\n",
    "  try:\n",
    "    embedding_matrix[i] = model[word]\n",
    "  except:\n",
    "    embedding_matrix[i] = [0.0]*100\n",
    "    ct+=1\n",
    "      \n",
    "print('{} out of {} words absent'.format(ct, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZXxym2czqtc"
   },
   "outputs": [],
   "source": [
    "def plot_neural_net_details(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def train_model(classifier, train, label, valid, model_name, epochs=2):\n",
    "    start = time.time()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, min_delta=0.0001)\n",
    "    model_checkpoint = ModelCheckpoint(model_name+'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)        \n",
    "    \n",
    "    history = classifier.fit(train, label, epochs=epochs, batch_size=32, validation_split=0.1,\n",
    "                             callbacks=[early_stopping, model_checkpoint])\n",
    "    \n",
    "    predictions = classifier.predict(valid)\n",
    "    print(\"Time taken: %.2f seconds\" % (time.time()-start))\n",
    "    plot_neural_net_details(history)\n",
    "    return predictions, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeUk0zNv-22M"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugdkV62B-gKY"
   },
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = Input((60, ))\n",
    "\n",
    "    embedding_layer = Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    conv_layer1 = Convolution1D(100, 3, activation=\"relu\")(embedding_layer)    \n",
    "    pooling_layer1 = GlobalMaxPool1D()(conv_layer1)\n",
    "    \n",
    "    output_layer1 = Dense(50, activation='relu')(pooling_layer1)\n",
    "    output_layer1 = Dropout(0.25)(output_layer1)\n",
    "    \n",
    "    output_layer2 = Dense(14, activation='softmax')(output_layer1)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_cnn()\n",
    "cnn_pred, cnn = train_model(classifier, train_seq_x, train_y, valid_seq_x, 'CNN', epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOl_qlxO-zMb"
   },
   "outputs": [],
   "source": [
    "print('CNN accuracy on test: %.3f' % (accuracy_score(np.argmax(cnn_pred, axis=1), valid_y.idxmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9wfYiqp-0MR"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7OKzu8e_G7v"
   },
   "outputs": [],
   "source": [
    "def create_bi_lstm():\n",
    "    input_layer = Input((60, ))\n",
    "\n",
    "    embedding_layer = Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    lstm_layer = Bidirectional(LSTM(100))(embedding_layer)\n",
    "\n",
    "    output_layer1 = Dense(50, activation='relu')(lstm_layer)\n",
    "    output_layer1 = Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = Dense(14, activation='softmax')(output_layer1)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_bi_lstm()\n",
    "bilstm_pred, bilstm = train_model(classifier, train_seq_x, train_y, valid_seq_x, 'Bi-LSTM', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pI_qwefo_HDw"
   },
   "outputs": [],
   "source": [
    "print('Bi-LSTM accuracy on test: %.3f' % (accuracy_score(np.argmax(bilstm_pred, axis=1), valid_y.idxmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxInKeVF_HYo"
   },
   "source": [
    "### R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afiWCN_kzsVr"
   },
   "outputs": [],
   "source": [
    "def create_rcnn():\n",
    "    input_layer = Input((60, ))\n",
    "    \n",
    "    embedding_layer = Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = SpatialDropout1D(0.3)(embedding_layer)\n",
    "        \n",
    "    rnn_layer = Bidirectional(GRU(50, return_sequences=True))(embedding_layer)\n",
    "    \n",
    "    conv_layer = Convolution1D(100, 3, activation=\"relu\")(rnn_layer)\n",
    "\n",
    "    pooling_layer = GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    output_layer1 = Dense(50, activation='relu')(pooling_layer)\n",
    "    output_layer1 = Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = Dense(14, activation='softmax')(output_layer1)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rcnn()\n",
    "rcnn_pred, rcnn = train_model(classifier, train_seq_x, train_y, valid_seq_x, 'R-CNN', epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-jXxIFD_EPB"
   },
   "outputs": [],
   "source": [
    "print('R-CNN accuracy on test: %.3f' % (accuracy_score(np.argmax(rcnn_pred, axis=1), valid_y.idxmax(axis=1))))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastText.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
